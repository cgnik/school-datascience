{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Twitter feed analysis for food sentiment\n",
    "Strategy: iterate over the bz2 tweet archive files and look for geographic distribution of negative sentiment regarding food, groceries, supermarkets, etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "546"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bz2\n",
    "import json\n",
    "from enum import Enum, auto\n",
    "\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "# DEFERRING: not going to pull the tweets - found an archive and i'll use that\n",
    "# tweets = run_search(['grocery', 'food', 'far', 'enough', 'hunger', 'hungry'])\n",
    "with open('data/tweets/files.txt') as f:\n",
    "    all_files = [l.strip().replace('./', 'data/tweets/') for l in f.readlines()]\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sample the files randomly to iterate them looking to build a word cloud"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "104"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_of_files = 0.20  # % of the archive files\n",
    "files = list({all_files[i] for i in np.random.randint(0, len(all_files), int(percent_of_files * len(all_files)))})\n",
    "len(files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# subset the tweets looking for specific terms\n",
    "filter_terms = frozenset(('food', 'eat', 'grocery', 'market', 'supermarket', 'travel', 'far', 'miles', ''))\n",
    "filter_count = len(filter_terms)\n",
    "filter_min = filter_count - 2  # have to match at least 2 words\n",
    "\n",
    "fails = {}\n",
    "\n",
    "\n",
    "class FailType(Enum):\n",
    "    PLACE = auto()\n",
    "    COORD = auto()\n",
    "    TEXT = auto()\n",
    "    COUNTRY = auto()\n",
    "\n",
    "\n",
    "def fail(t: FailType):\n",
    "    fails[t] = fails.get(t, 0) + 1\n",
    "\n",
    "\n",
    "# coordinates can apparently happen in any of the following, according to\n",
    "# jq -c 'paths | select(.[-1] == \"coordinates\")' test.json | sort | uniq\n",
    "# [\"coordinates\"]\n",
    "# [\"coordinates\",\"coordinates\"]\n",
    "# [\"geo\",\"coordinates\"]\n",
    "# [\"place\",\"bounding_box\",\"coordinates\"]\n",
    "def filter_tweets(t):\n",
    "    if t is None:\n",
    "        return False\n",
    "    # only care if it's in the US\n",
    "    place = t.get('place') or {}\n",
    "    # if not place or place.get('country_code') != 'US':\n",
    "    #     fail(FailType.COUNTRY)\n",
    "    #     return False\n",
    "    # only care if we can place it\n",
    "    box = place.get('bounding_box')\n",
    "    if not box or not box.get('coordinates'):\n",
    "        fail(FailType.COORD)\n",
    "        return False\n",
    "    text = t.get('text').lower()\n",
    "    # only care if it mentions at least 2 of the keywords\n",
    "    if len(filter_terms.difference(set(text.split()))) > filter_min:\n",
    "        fail(FailType.TEXT)\n",
    "        return False\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data/tweets/2021/01/06/08/33.json.bz2 (99%)\n",
      "Failures: {<FailType.COORD: 2>: 447676, <FailType.TEXT: 3>: 2103}\n",
      "Gathered 0 matching tweets\n",
      "EXAMPLE: {}\n"
     ]
    }
   ],
   "source": [
    "from ds.tweet import analyse_sentiment\n",
    "\n",
    "tweets = []\n",
    "\n",
    "\n",
    "def file_gen(file_list):\n",
    "    for f in file_list:\n",
    "        yield f\n",
    "    return\n",
    "\n",
    "\n",
    "def scan_file(file_name):\n",
    "    tweets = []\n",
    "    with bz2.open(file_name, 'rt', encoding=\"utf-8\", newline='\\r\\n') as f:\n",
    "        for line in f.readlines():\n",
    "            t = json.loads(line)\n",
    "            if not t:\n",
    "                raise IOError(f\"Unable to translate '{line}' into json\")\n",
    "            if filter_tweets(t):\n",
    "                tweets.append(t)\n",
    "    return tweets\n",
    "\n",
    "\n",
    "with mp.Pool(mp.cpu_count() - 2) as pool:\n",
    "    # for i, file_name in enumerate(files):\n",
    "    count = len(files)\n",
    "    finished = 0\n",
    "    for response in pool.imap(scan_file, file_gen):\n",
    "        finished += 1\n",
    "        if isinstance(response, Exception):\n",
    "            print(f\"ERROR ERROR {response}\")\n",
    "        else:\n",
    "            tweets += response\n",
    "            print(f\"\\r{finished}/{len(files)}: {int(100 * finished / len(files))}% complete...\", end='')\n",
    "print(\n",
    "    f\"\\nFailures: {fails}\\nGathered {len(tweets)} matching tweets\\nEXAMPLE: {tweets[0] if len(tweets) > 0 else 'None'}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "applicable = list(filter(filter_tweets, tweets))\n",
    "sentiments = [(TextBlob(t.get('text')), t) for t in applicable]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for b, t in sentiments:\n",
    "#     print(f\"ANALYSIS: {b.sentiment} {b.tags} {b.sentiment_assessments}\")\n",
    "len(sentiments)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}